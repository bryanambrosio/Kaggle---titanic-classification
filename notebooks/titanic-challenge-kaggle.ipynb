{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport joblib\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-03T12:16:56.461410Z","iopub.execute_input":"2025-02-03T12:16:56.461824Z","iopub.status.idle":"2025-02-03T12:16:57.493785Z","shell.execute_reply.started":"2025-02-03T12:16:56.461777Z","shell.execute_reply":"2025-02-03T12:16:57.492524Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ntrain_data.head()\ntest_ids = test_data[\"PassengerId\"]\n#test_data.head()\n\ndef clean(train_data):\n    train_data = train_data.drop([\"Ticket\", \"Cabin\", \"Name\", \"PassengerId\"], axis=1)\n    \n    cols = [\"SibSp\", \"Parch\", \"Fare\", \"Age\"]\n    for col in cols:\n        train_data[col].fillna(train_data[col].median())\n\n    train_data.Embarked.fillna(\"U\")\n    return train_data\n\ntrain_data = clean(train_data)\ntest_data = clean(test_data)\ntrain_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T12:16:57.496307Z","iopub.execute_input":"2025-02-03T12:16:57.496804Z","iopub.status.idle":"2025-02-03T12:16:57.563366Z","shell.execute_reply.started":"2025-02-03T12:16:57.496769Z","shell.execute_reply":"2025-02-03T12:16:57.562217Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n0         0       3    male  22.0      1      0   7.2500        S\n1         1       1  female  38.0      1      0  71.2833        C\n2         1       3  female  26.0      0      0   7.9250        S\n3         1       1  female  35.0      1      0  53.1000        S\n4         0       3    male  35.0      0      0   8.0500        S","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\n\ncols = [\"Sex\", \"Embarked\"]\n\nfor col in cols:\n    train_data[col] = le.fit_transform(train_data[col])\n    test_data[col] = le.transform(test_data[col])\n    print(le.classes_)\n\ntrain_data.head(5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T12:16:57.564648Z","iopub.execute_input":"2025-02-03T12:16:57.565054Z","iopub.status.idle":"2025-02-03T12:16:58.889938Z","shell.execute_reply.started":"2025-02-03T12:16:57.565008Z","shell.execute_reply":"2025-02-03T12:16:58.888823Z"}},"outputs":[{"name":"stdout","text":"['female' 'male']\n['C' 'Q' 'S' nan]\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n0         0       3    1  22.0      1      0   7.2500         2\n1         1       1    0  38.0      1      0  71.2833         0\n2         1       3    0  26.0      0      0   7.9250         2\n3         1       1    0  35.0      1      0  53.1000         2\n4         0       3    1  35.0      0      0   8.0500         2","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"def check_missing_values(data, dataset_name):\n    missing_values = data.isnull().sum()  # Soma de valores ausentes por coluna\n    total_missing = missing_values.sum()  # Soma total de valores ausentes\n    if total_missing > 0:\n        print(f\"Conjunto {dataset_name} possui {total_missing} valores ausentes.\")\n        print(\"Valores ausentes por coluna:\")\n        print(missing_values[missing_values > 0])  # Exibir apenas colunas com valores ausentes\n    else:\n        print(f\"Conjunto {dataset_name} não possui valores ausentes.\")\n\ncheck_missing_values(train_data, \"train_data\")\ncheck_missing_values(test_data, \"test_data\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T12:16:58.891292Z","iopub.execute_input":"2025-02-03T12:16:58.891920Z","iopub.status.idle":"2025-02-03T12:16:58.903851Z","shell.execute_reply.started":"2025-02-03T12:16:58.891864Z","shell.execute_reply":"2025-02-03T12:16:58.902601Z"}},"outputs":[{"name":"stdout","text":"Conjunto train_data possui 177 valores ausentes.\nValores ausentes por coluna:\nAge    177\ndtype: int64\nConjunto test_data possui 87 valores ausentes.\nValores ausentes por coluna:\nAge     86\nFare     1\ndtype: int64\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Calcular a média de \"Fare\" no test_data\nfare_mean = test_data[\"Fare\"].mean()\n\n# Imputar valores ausentes em \"Fare\" com a média\ntest_data[\"Fare\"] = test_data[\"Fare\"].fillna(fare_mean)\n# Calcular a média de \"Age\" nos conjuntos de dados\nage_mean_train = train_data[\"Age\"].mean()\nage_mean_test = test_data[\"Age\"].mean()\n\n# Imputar valores ausentes em \"Age\" com a média\ntrain_data[\"Age\"] = train_data[\"Age\"].fillna(age_mean_train)\ntest_data[\"Age\"] = test_data[\"Age\"].fillna(age_mean_test)\n\n# Verificar se os valores ausentes foram tratados\nprint(\"Valores ausentes em train_data:\")\nprint(train_data.isnull().sum())\n\nprint(\"\\nValores ausentes em test_data:\")\nprint(test_data.isnull().sum())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T12:16:58.905449Z","iopub.execute_input":"2025-02-03T12:16:58.905953Z","iopub.status.idle":"2025-02-03T12:16:58.932905Z","shell.execute_reply.started":"2025-02-03T12:16:58.905906Z","shell.execute_reply":"2025-02-03T12:16:58.931680Z"}},"outputs":[{"name":"stdout","text":"Valores ausentes em train_data:\nSurvived    0\nPclass      0\nSex         0\nAge         0\nSibSp       0\nParch       0\nFare        0\nEmbarked    0\ndtype: int64\n\nValores ausentes em test_data:\nPclass      0\nSex         0\nAge         0\nSibSp       0\nParch       0\nFare        0\nEmbarked    0\ndtype: int64\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\ny = train_data[\"Survived\"]\nX = train_data.drop(\"Survived\", axis=1)\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T12:16:58.934385Z","iopub.execute_input":"2025-02-03T12:16:58.934820Z","iopub.status.idle":"2025-02-03T12:16:59.254193Z","shell.execute_reply.started":"2025-02-03T12:16:58.934774Z","shell.execute_reply":"2025-02-03T12:16:59.252943Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"clf = LogisticRegression(random_state=0, max_iter=1000).fit(X_train, y_train)\n# Salvar o modelo\njoblib.dump(clf, 'titanic_model.pkl')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T12:16:59.257653Z","iopub.execute_input":"2025-02-03T12:16:59.258096Z","iopub.status.idle":"2025-02-03T12:16:59.297454Z","shell.execute_reply.started":"2025-02-03T12:16:59.258048Z","shell.execute_reply":"2025-02-03T12:16:59.296364Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"['titanic_model.pkl']"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"predictions = clf.predict(X_val)\nfrom sklearn.metrics import accuracy_score\naccuracy_score(y_val, predictions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T12:16:59.298780Z","iopub.execute_input":"2025-02-03T12:16:59.299180Z","iopub.status.idle":"2025-02-03T12:16:59.311785Z","shell.execute_reply.started":"2025-02-03T12:16:59.299137Z","shell.execute_reply":"2025-02-03T12:16:59.310378Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"0.8100558659217877"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"submission_preds = clf.predict(test_data)\n\n# Agora, ambos têm o mesmo comprimento\ndf = pd.DataFrame({\n    \"PassengerId\": test_ids.values,\n    \"Survived\": submission_preds\n})\n\ndf.to_csv(\"submission.csv\", index=False)\n\n\nimport os\nprint(os.getcwd())  # Mostra o diretório atual\nprint(\"Arquivo salvo como submission.csv\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T12:16:59.313167Z","iopub.execute_input":"2025-02-03T12:16:59.313550Z","iopub.status.idle":"2025-02-03T12:16:59.335021Z","shell.execute_reply.started":"2025-02-03T12:16:59.313514Z","shell.execute_reply":"2025-02-03T12:16:59.333652Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\nArquivo salvo como submission.csv\n","output_type":"stream"}],"execution_count":9}]}